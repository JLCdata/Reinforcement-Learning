{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1: Programación dinámica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from grid_world import GridWorld\n",
    "from utils import display_policy\n",
    "from utils import display_value_function\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte I"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Describa el MDP que define al problema (espacio de estados, espacio de acciones, función de recompensa y función de transición de estados).***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Espacio de estados:\n",
    "* Espacio de acciones:\n",
    "* Función de recompensa:\n",
    "* Función de transición de estados:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Programe el algoritmo “policy iteration” para resolver el problema propuesto. Para ello complete\n",
    "los métodos policy evaluation y policy improvement que se encuentran en el archivo\n",
    "policy iteration.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'left', '1': 'right', '2': 'up', '3': 'down'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_dictionary={\"0\":\"left\",\"1\":\"right\",\"2\":\"up\",\"3\":\"down\"}\n",
    "action_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_with_probability(a, b, p):\n",
    "    if np.random.uniform() < p:\n",
    "        return a\n",
    "    else:\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_array(arreglo1, arreglo2):\n",
    "    resultado = ()\n",
    "    for elemento1, elemento2 in zip(arreglo1, arreglo2):\n",
    "        suma = elemento1 + elemento2\n",
    "        resultado += (suma,)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition_function(s,a,p_random,reward_grid):\n",
    "\n",
    "    # Se guarda estado inicial\n",
    "    initial_state=s\n",
    "\n",
    "    # Según la acción que se ejecuta, se definen los dos potenciales movimientos efectivos que podrian suceder (verticales a la acción original)\n",
    "\n",
    "    # Acciones 0 o 1\n",
    "    if (a==0) or (a==1):\n",
    "\n",
    "        x=2\n",
    "        y=3\n",
    "\n",
    "        # Elección del movimiento x o y con probabilidad p_random\n",
    "        final_action=choose_with_probability(x,y,p_random)\n",
    "\n",
    "        # Según la acción final, se define el delta state que permite obtener el nuevo potencial estado\n",
    "        delta_state=(0,1) if  final_action==2  else  (0,-1)\n",
    "\n",
    "        # Se obtiene el nuevo potencial estado mediante suma vectorial\n",
    "        potential_new_state=sum_array(initial_state, delta_state)\n",
    "\n",
    "        # Permanecemos en el estado inicial si es que no se puede recorrer dicho estado sino, vamos al nuevo estado\n",
    "        final_state=initial_state if np.isnan(reward_grid[potential_new_state]) else potential_new_state\n",
    "        \n",
    "        return final_state,reward_grid[final_state]\n",
    "\n",
    "    else: # Acciones 2 o 3\n",
    "\n",
    "        # Código analogo\n",
    "        x=0\n",
    "        y=1\n",
    "        final_action=choose_with_probability(x,y,p_random)\n",
    "        delta_state=(-1,0) if final_action==0 else (1,0) \n",
    "        potential_new_state=sum_array(initial_state, delta_state)\n",
    "        final_state=initial_state if np.isnan(reward_grid[potential_new_state]) else potential_new_state\n",
    "\n",
    "        return final_state,reward_grid[final_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyIterator():\n",
    "    \n",
    "    def __init__(self, reward_grid, wall_value, cell_value, terminal_value):\n",
    "\n",
    "        self._reward_grid = reward_grid\n",
    "        self._wall_value = wall_value\n",
    "        self._cell_value = cell_value\n",
    "        self._terminal_value = terminal_value\n",
    "\n",
    "        self._value_function = np.zeros(self._reward_grid.shape)\n",
    "        self._value_function *= self._reward_grid\n",
    "        self._policy = self._value_function.copy()\n",
    "\n",
    "\n",
    "    def _policy_evaluation(self, nb_iters, p_dir, gamma, v_thresh):\n",
    "        # Policy evaluation\n",
    "        # Code your algorithm here (P1-2) (you can add auxiliary functions if needed)\n",
    "        #policy_probs=np.full((5,5,4),0.25)\n",
    "        prob=0.25\n",
    "        p_random    = 1 - p_dir\n",
    "        #p_side\n",
    "        value_rows, value_cols = self._value_function.shape\n",
    "\n",
    "        delta=float(\"inf\")\n",
    "        for _ in range(nb_iters):\n",
    "\n",
    "            # Indexes for skipping external walls (you may change them)\n",
    "            for j in range(1, value_rows - 1):\n",
    "                for i in range(1, value_cols - 1):\n",
    "                    \n",
    "                    old_value=self._value_function[(j,i)]\n",
    "                    new_value=0\n",
    "\n",
    "                    for action in range(4):\n",
    "\n",
    "                        next_state,reward=state_transition_function((j,i),action,p_random,self._reward_grid)\n",
    "                        \n",
    "                        new_value+=prob*(reward+gamma*self._value_function[next_state])\n",
    "\n",
    "                        delta=max(delta,abs(old_value,new_value))\n",
    "                    \n",
    "            if delta < v_thresh:\n",
    "                break\n",
    "            \n",
    "                    \n",
    "    def _policy_improvement(self, nb_iters, p_dir, gamma):\n",
    "        # Policy improvement\n",
    "        # Code your algorithm here (P1-2) (you can add auxiliary functions if needed)\n",
    "        \n",
    "        p_random    = 1 - p_dir\n",
    "        value_rows, value_cols = self._value_function.shape\n",
    "\n",
    "        old_policy = self._policy.copy()\n",
    "        stable_policy = True\n",
    "\n",
    "        for j in range(1, value_rows - 1):\n",
    "            for i in range(1, value_cols - 1):\n",
    "                \n",
    "                \"\"\"if something:\n",
    "                    stable_policy = False\n",
    "                \"\"\"\n",
    "        \n",
    "        return stable_policy\n",
    "\n",
    "\n",
    "    def run_policy_iteration(self, p_dir, nb_iters, gamma, v_thresh):\n",
    "        stable_policy = False\n",
    "\n",
    "        while not stable_policy:\n",
    "            self._policy_evaluation(nb_iters, p_dir, gamma, v_thresh)\n",
    "            stable_policy = self._policy_improvement(nb_iters, p_dir, gamma)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "world = GridWorld(height=14, width=16)\n",
    "policy_iterator = PolicyIterator(reward_grid=world._rewards,\n",
    "                                    wall_value=None,\n",
    "                                    cell_value=-1,\n",
    "                                    terminal_value=0)\n",
    "\n",
    "# Default parameters for P1-3 (change them for P2-3)\n",
    "policy_iterator.run_policy_iteration(p_dir=0.8,\n",
    "                                        nb_iters=1000,\n",
    "                                        gamma=0.9,\n",
    "                                        v_thresh=0.0001)\n",
    "\n",
    "world.display()\n",
    "\n",
    "display_value_function(policy_iterator._value_function)\n",
    "\n",
    "display_policy(world._grid,\n",
    "                policy_iterator._reward_grid,\n",
    "                policy_iterator._policy)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sin modificar las funciones auxiliares proporcionadas en el código base, muestre la función de valor\n",
    "encontrada, junto a la política aprendida, y el núimero de iteraciones sobre la función de valor que fue\n",
    "necesario realizar.***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    \n",
    "    def __init__(self, height, width):\n",
    "        \n",
    "        # World parameters\n",
    "        self._height     =   height\n",
    "        self._width      =   width\n",
    "        self._grid       =   np.ones((self._height, self._width))\n",
    "        self._rewards    = - np.ones((self._height, self._width))\n",
    "\n",
    "        self._construct_world(self._grid, 0, 1, 0.5)\n",
    "        self._construct_world(self._rewards, np.nan, -1, 0)\n",
    "\n",
    "\n",
    "    # Private methods\n",
    "    def _construct_world(self, grid, wall_value, cell_value, terminal_value):\n",
    "        \n",
    "        # External Walls\n",
    "        grid[0, 0:]                 = wall_value\n",
    "        grid[self._height - 1, 0:]  = wall_value\n",
    "        grid[0:, self._width - 1]   = wall_value\n",
    "        grid[0:, 0]                 = wall_value\n",
    "        \n",
    "        # Internal Walls\n",
    "        grid[5, 0:]                 = wall_value\n",
    "        grid[5, 5]                  = cell_value\n",
    "        grid[8:, 4]                 = wall_value\n",
    "        \n",
    "        # Terminal state\n",
    "        grid[self._height - 2, self._width - 2] = terminal_value\n",
    "\n",
    "\n",
    "    # Public methods\n",
    "    def display(self):\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        for j in range(self._height):\n",
    "            for i in range(self._width):\n",
    "                if self._rewards[j, i] == 0:\n",
    "                    ax.text(i, j, 'G', ha='center', va='center')\n",
    "                elif self._rewards[j , i] != None:\n",
    "                    ax.text(i, j, self._rewards[j, i], ha='center', va='center')\n",
    "\n",
    "        ax.imshow(self._grid, cmap='gray')\n",
    "        \n",
    "        plt.title('Grid World')\n",
    "        plt.axis('off')\n",
    "        fig.tight_layout()\n",
    "\n",
    "        plt.savefig('world.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(world._rewards[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = GridWorld(height=14, width=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25]],\n",
       "\n",
       "       [[0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25]],\n",
       "\n",
       "       [[0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25]],\n",
       "\n",
       "       [[0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25]],\n",
       "\n",
       "       [[0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_probs=np.full((5,5,4),0.25)\n",
    "policy_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toma como un input un estado y entrega las probabilidades de tomar cada acción en ese estado\n",
    "def policy(state):\n",
    "\n",
    "    return policy_probs[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.25, 0.25, 0.25])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estado (4,4)\n",
    "policy((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Representa el valor de todos los estados\n",
    "state_values=np.zeros(shape=(14,16))\n",
    "state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(policy_probs,state_values,theta=1e-6,gamma=0.99):\n",
    "    delta=float(\"inf\")\n",
    "\n",
    "    while delta >theta:\n",
    "        delta=0\n",
    "\n",
    "        for row in range(14):\n",
    "            for col in range(16):\n",
    "                \n",
    "                old_value=state_values[(row,col)]\n",
    "                new_value=0\n",
    "                action_probabilities=policy_probs[(row,col)]\n",
    "\n",
    "                for action,prob in enumerate(action_probabilities):\n",
    "                    next_state,reward=simulate_step((row,col),action)\n",
    "                    new_value+=prob*(reward+gamma*state_values[next_state])\n",
    "                state_values[(row,col)]=new_value\n",
    "\n",
    "                delta=max(delta,abs(old_value,new_value))\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(policy_probs,state_values,gamma=0.99):\n",
    "    policy_stable=True\n",
    "    for row in range(14):\n",
    "            for col in range(16):\n",
    "                old_action=policy_probs[(row,col)].argmax()\n",
    "                new_action=None\n",
    "                max_qsa=float(\"-inf\") \n",
    "\n",
    "                for action in range(4):\n",
    "                    next_sate,reward,_,_=simulated_step((row,col),action)\n",
    "                    qsa=reward+gamma*state_values[next_sate]\n",
    "\n",
    "                    if qsa>max_qsa:\n",
    "                        new_action=action\n",
    "                        max_qsa=qsa\n",
    "                    action_probs=np.zeros(4)\n",
    "                    action_probs[new_action]=1\n",
    "                    policy_probs[(row,col)]=action_probs\n",
    "\n",
    "                    if new_action!=old_action:\n",
    "                         policy_stable=False\n",
    "    \n",
    "    return policy_stable\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def policy_iteration(policy_probs,state_values,theta=0.001,gamma=0.99):\n",
    "    policy_stable=False\n",
    "    while not policy_stable:\n",
    "        policy_evaluation(policy_probs,state_values,theta,gamma)\n",
    "        plot_values(state_values,frame)\n",
    "        policy_stable=policy_improvement(policy_probs,state_values,gamma)\n",
    "        plot_policy(policy_probs,frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anglo_american",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
