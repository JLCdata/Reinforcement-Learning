{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. y 3. Deep Q-Network (I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from replay_buffer import ReplayBuffer\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from replay_buffer import ReplayBuffer\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_states, dim_actions):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        # MLP, fully connected layers, ReLU activations, linear ouput activation\n",
    "        # dim_states -> 64 -> 64 -> dim_actions\n",
    "\n",
    "        # Inicialización de pesos con distribución uniforme\n",
    "        def init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "\n",
    "                #nn.init.normal_(m.weight, mean=0.0, std=1)\n",
    "                #nn.init.normal_(m.weight, mean=0.0, std=1)\n",
    "                nn.init.uniform_(m.weight, a=0.0, b=1.0)\n",
    "                nn.init.uniform_(m.bias, a=0.0, b=1.0)\n",
    "                \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(dim_states, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, dim_actions)\n",
    "        )\n",
    "\n",
    "        self.layers.apply(init_weights)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        # tensor format\n",
    "        if isinstance(input, torch.Tensor):\n",
    "            input=input\n",
    "            \n",
    "        else:\n",
    "            input = torch.from_numpy(input).unsqueeze(dim=0).float()\n",
    "            \n",
    "        q_values = self.layers(input)\n",
    "\n",
    "        return q_values\n",
    "\n",
    "class DeepQNetworkAgent:\n",
    "\n",
    "    def __init__(self, dim_states, dim_actions, lr, gamma, epsilon, nb_training_steps, replay_buffer_size, batch_size):\n",
    "        \n",
    "        self._learning_rate = lr\n",
    "        self._gamma = gamma\n",
    "        self._epsilon = epsilon\n",
    "\n",
    "        self._epsilon_min = 0.0\n",
    "        self._epsilon_decay = self._epsilon / (nb_training_steps / 2.)\n",
    "\n",
    "        self._dim_states = dim_states\n",
    "        self._dim_actions = dim_actions\n",
    "\n",
    "        self.replay_buffer = ReplayBuffer(dim_states=self._dim_states,\n",
    "                                          dim_actions=self._dim_actions,\n",
    "                                          max_size=replay_buffer_size,\n",
    "                                          sample_size=batch_size)\n",
    "\n",
    "        # Complete\n",
    "        self._deep_qnetwork = DeepQNetwork(self._dim_states, self._dim_actions)\n",
    "        self._target_deepq_network = copy.deepcopy(self._deep_qnetwork).eval()\n",
    "\n",
    "        # Adam optimizer\n",
    "        self._optimizer = AdamW(self._deep_qnetwork.parameters(), lr=self._learning_rate)\n",
    "\n",
    "\n",
    "    def store_transition(self, s_t, a_t, r_t, s_t1, done_t):\n",
    "        self.replay_buffer.store_transition(s_t, a_t, r_t, s_t1, done_t)\n",
    "\n",
    "\n",
    "    def replace_target_network(self):\n",
    "        self._target_deepq_network.load_state_dict(self._deep_qnetwork.state_dict())\n",
    "        \n",
    "\n",
    "    def select_action(self, observation, greedy=False):\n",
    "        \n",
    "           \n",
    "            if np.random.random() > self._epsilon or greedy:\n",
    "                # Select action greedily\n",
    "\n",
    "                # Action values\n",
    "                qa = self._deep_qnetwork(observation)\n",
    "\n",
    "                # Action con mayor q-value\n",
    "                action=qa.argmax().item()\n",
    "        \n",
    "            else:\n",
    "                # Exploración\n",
    "                action=np.random.randint(2)\n",
    "\n",
    "            if not greedy and self._epsilon >= self._epsilon_min:\n",
    "                \n",
    "                # Implement epsilon linear decay\n",
    "                self._epsilon-=self._epsilon_decay \n",
    "                \n",
    "\n",
    "            return action\n",
    "\n",
    "    def update(self):\n",
    "        s_t,a_t,r_t,s_t1,done=self.replay_buffer.sample_transitions()\n",
    "\n",
    "        s_t=torch.from_numpy(s_t).unsqueeze(dim=0).float()\n",
    "        s_t1=torch.from_numpy(s_t1).unsqueeze(dim=0).float()\n",
    "        r_t = torch.tensor(r_t).view(-1, 1).float()\n",
    "        done = torch.tensor(done).view(-1, 1)\n",
    "        a_t=torch.tensor(a_t).view(-1, 1).type(torch.int64)\n",
    "\n",
    "        # Predict Q-value de estado actual\n",
    "        qsa_predict=self._deep_qnetwork(s_t)\n",
    "        qsa_actions=torch.gather(input=qsa_predict[0], dim=1,index = a_t)\n",
    "        \n",
    "        # Calculo de Q-value target (Q-value estado siguiente)\n",
    "        next_qsa_predict=self._target_deepq_network(s_t1)\n",
    "        max_next_qsa_predict=torch.max(next_qsa_predict, dim=-1, keepdim=True)[0][0]\n",
    "\n",
    "        target_qsa=r_t+~done*self._gamma*max_next_qsa_predict\n",
    "\n",
    "        loss = F.mse_loss(qsa_actions, target_qsa)\n",
    "        self._deep_qnetwork.zero_grad()\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "eval_env = gym.make('CartPole-v1')\n",
    "\n",
    "# Actions are discrete\n",
    "dim_actions = np.array(env.action_space.n)\n",
    "\n",
    "# States are continuous\n",
    "dim_states = env.observation_space.shape[0]\n",
    "\n",
    "print(dim_states)\n",
    "print(dim_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepQNetwork(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_qnetwork = DeepQNetwork(dim_states, dim_actions)\n",
    "deep_qnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepQNetwork(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_deepq_network = copy.deepcopy(deep_qnetwork).eval()\n",
    "target_deepq_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00950862,  0.02172191, -0.02052333, -0.00567765], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation=env.reset()\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[579.1338, 609.3038]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qsa=deep_qnetwork(observation)\n",
    "qsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0095,  0.0217, -0.0205, -0.0057]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = torch.from_numpy(observation).unsqueeze(dim=0).float()\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[579.1338, 609.3038]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qsa=deep_qnetwork(observation)\n",
    "qsa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \n",
    "    def __init__(self, dim_states, dim_actions, max_size, sample_size):\n",
    "\n",
    "        assert sample_size < max_size, \"Sample size cannot be greater than buffer size\"\n",
    "        \n",
    "        self._buffer_idx     = 0\n",
    "        self._exps_stored    = 0\n",
    "        self._buffer_size    = max_size\n",
    "        self._sample_size    = sample_size\n",
    "\n",
    "        self._s_t_array      = np.zeros((max_size, dim_states))\n",
    "        self._a_t_array      = np.zeros((max_size))\n",
    "        self._r_t_array      = np.zeros((max_size,))\n",
    "        self._s_t1_array     = np.zeros((max_size, dim_states))\n",
    "        self._term_t_array   = np.zeros((max_size,), dtype=bool)\n",
    "\n",
    "\n",
    "    def store_transition(self, s_t, a_t, r_t, s_t1, done_t):\n",
    "\n",
    "        # Add transition to replay buffer according to self._buffer_idx\n",
    "        self._s_t_array[self._buffer_idx]=s_t   \n",
    "        self._a_t_array[self._buffer_idx]=a_t  \n",
    "        self._r_t_array[self._buffer_idx]=r_t  \n",
    "        self._s_t1_array[self._buffer_idx]=s_t1 \n",
    "        self._term_t_array[self._buffer_idx]=done_t\n",
    "\n",
    "        # Update replay buffer index\n",
    "        # Aumento de indice y reinicio de indice si superamos capacidad\n",
    "        self._buffer_idx = (self._buffer_idx + 1) % self._buffer_size\n",
    "        self._exps_stored += 1\n",
    "\n",
    "    \n",
    "    def sample_transitions(self):\n",
    "        assert self._exps_stored + 1 > self._sample_size, \"Not enough samples have been stored to start sampling\"\n",
    "        \n",
    "        sample_idxs = np.random.choice(self._buffer_size, size=self._sample_size,replace=False)\n",
    "        \n",
    "        return (self._s_t_array[sample_idxs],\n",
    "                self._a_t_array[sample_idxs],\n",
    "                self._r_t_array[sample_idxs],\n",
    "                self._s_t1_array[sample_idxs],\n",
    "                self._term_t_array[sample_idxs])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Ambiente: CartPole\n",
    "env = gym.make('CartPole-v1')\n",
    "eval_env = gym.make('CartPole-v1')\n",
    "\n",
    "# Actions are discrete\n",
    "dim_actions = np.array(env.action_space.n)\n",
    "\n",
    "# States are continuous\n",
    "dim_states = env.observation_space.shape[0]\n",
    "\n",
    "print(dim_states)\n",
    "print(dim_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de memory Buffer\n",
    "max_size=5\n",
    "sample_size=3\n",
    "memory=ReplayBuffer(dim_states, dim_actions, max_size, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04151405  0.16197139 -0.02788865 -0.289783  ] 1.0 False\n",
      "[-0.03827462 -0.03274201 -0.03368431 -0.00602468] 1.0 False\n",
      "[-0.03892946 -0.22736509 -0.03380481  0.27584302] 1.0 False\n",
      "[-0.04347676 -0.03177756 -0.02828795 -0.02730738] 1.0 False\n",
      "[-0.04411231 -0.22648266 -0.0288341   0.25631788] 1.0 False\n",
      "[-0.04864197 -0.03096115 -0.02370774 -0.04531853] 1.0 False\n"
     ]
    }
   ],
   "source": [
    "# Simulación de 6 transiciones\n",
    "s_t=env.reset()\n",
    "\n",
    "for i in range(6):\n",
    "   \n",
    "    a_t=np.random.randint(2)\n",
    "    s_t1, r_t, done_t, _ = env.step(a_t)\n",
    "    print(s_t1, r_t, done_t)\n",
    "\n",
    "    # Guardar\n",
    "    memory.store_transition(s_t, a_t, r_t, s_t1, done_t)\n",
    "\n",
    "    s_t = s_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04864197, -0.03096115, -0.02370774, -0.04531853],\n",
       "       [-0.03827462, -0.03274201, -0.03368431, -0.00602468],\n",
       "       [-0.03892946, -0.22736509, -0.03380481,  0.27584302],\n",
       "       [-0.04347676, -0.03177756, -0.02828795, -0.02730738],\n",
       "       [-0.04411231, -0.22648266, -0.0288341 ,  0.25631788]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos almacenados: Conjunto de estados almacenados\n",
    "memory._s_t1_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se observa como el sexto elemento de la transición de estados, coincide con el primer elemento del conjunto de estados almacenados. Esto debido a que la data se va sobreescribiendo en la medida de que hay nuevos registros.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se guardan a los 5 elementos, los cuales son el max_size del buffer\n",
    "memory._s_t1_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.04151405,  0.16197139, -0.02788865, -0.289783  ],\n",
       "        [-0.03827462, -0.03274201, -0.03368431, -0.00602468],\n",
       "        [-0.03892946, -0.22736509, -0.03380481,  0.27584302]]),\n",
       " array([0., 0., 1.]),\n",
       " array([1., 1., 1.]),\n",
       " array([[-0.03827462, -0.03274201, -0.03368431, -0.00602468],\n",
       "        [-0.03892946, -0.22736509, -0.03380481,  0.27584302],\n",
       "        [-0.04347676, -0.03177756, -0.02828795, -0.02730738]]),\n",
       " array([False, False, False]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "memory.sample_transitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se observa el muestreo de 3 elementos para el conjunto de estados\n",
    "len(memory.sample_transitions()[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de la dinámica RN y Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t,a_t,r_t,s_t1,done=memory.sample_transitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0389, -0.2274, -0.0338,  0.2758],\n",
       "         [-0.0441, -0.2265, -0.0288,  0.2563],\n",
       "         [-0.0415,  0.1620, -0.0279, -0.2898]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_t=torch.from_numpy(s_t).unsqueeze(dim=0).float()\n",
    "s_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0435, -0.0318, -0.0283, -0.0273],\n",
       "         [-0.0486, -0.0310, -0.0237, -0.0453],\n",
       "         [-0.0383, -0.0327, -0.0337, -0.0060]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_t1=torch.from_numpy(s_t1).unsqueeze(dim=0).float()\n",
    "s_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_t = torch.tensor(r_t).view(-1, 1).float()\n",
    "r_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done = torch.tensor(done).view(-1, 1)\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t=torch.tensor(a_t).view(-1, 1).type(torch.int64)\n",
    "a_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[552.4636, 581.1867],\n",
      "         [542.0415, 570.2692],\n",
      "         [477.6007, 502.9378]]], grad_fn=<AddBackward0>)\n",
      "tensor([[581.1867],\n",
      "        [570.2692],\n",
      "        [477.6007]], grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Predict Q-value de estado actual\n",
    "qsa_predict=deep_qnetwork(s_t)\n",
    "print(qsa_predict)\n",
    "qsa_actions=torch.gather(input=qsa_predict[0], dim=1,index = a_t)\n",
    "print(qsa_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qsa_actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[502.1877, 528.6159],\n",
       "         [492.4728, 518.4399],\n",
       "         [513.3165, 540.2734]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo de Q-value target (Q-value estado siguiente)\n",
    "next_qsa_predict=target_deepq_network(s_t1)\n",
    "next_qsa_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[528.6159],\n",
       "        [518.4399],\n",
       "        [540.2734]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_next_qsa_predict=torch.max(next_qsa_predict, dim=-1, keepdim=True)[0][0]\n",
    "max_next_qsa_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma=0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[524.3298],\n",
       "        [514.2556],\n",
       "        [535.8707]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_qsa=r_t+~done*gamma*max_next_qsa_predict\n",
    "target_qsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_qsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(deep_qnetwork.parameters(), lr=0.001)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.mse_loss(qsa_actions, target_qsa)\n",
    "deep_qnetwork.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read métricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_11_1=pd.read_csv(\"exp_11_1.csv\")\n",
    "exp_11_2=pd.read_csv(\"exp_11_2.csv\")\n",
    "exp_11_3=pd.read_csv(\"exp_11_3.csv\")\n",
    "exp_11_4=pd.read_csv(\"exp_11_4.csv\")\n",
    "exp_11_5=pd.read_csv(\"exp_11_5.csv\")\n",
    "\n",
    "exp_12_1=pd.read_csv(\"exp_12_1.csv\")\n",
    "exp_12_2=pd.read_csv(\"exp_12_2.csv\")\n",
    "exp_12_3=pd.read_csv(\"exp_12_3.csv\")\n",
    "exp_12_4=pd.read_csv(\"exp_12_4.csv\")\n",
    "exp_12_5=pd.read_csv(\"exp_12_5.csv\")\n",
    "\n",
    "exp_13_1=pd.read_csv(\"exp_13_1.csv\")\n",
    "exp_13_2=pd.read_csv(\"exp_13_2.csv\")\n",
    "exp_13_3=pd.read_csv(\"exp_13_3.csv\")\n",
    "exp_13_4=pd.read_csv(\"exp_13_4.csv\")\n",
    "exp_13_5=pd.read_csv(\"exp_13_5.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_21_1=pd.read_csv(\"exp_21_1.csv\")\n",
    "exp_21_2=pd.read_csv(\"exp_21_2.csv\")\n",
    "exp_21_3=pd.read_csv(\"exp_21_3.csv\")\n",
    "exp_21_4=pd.read_csv(\"exp_21_4.csv\")\n",
    "exp_21_5=pd.read_csv(\"exp_21_5.csv\")\n",
    "\n",
    "exp_22_1=pd.read_csv(\"exp_22_1.csv\")\n",
    "exp_22_2=pd.read_csv(\"exp_22_2.csv\")\n",
    "exp_22_3=pd.read_csv(\"exp_22_3.csv\")\n",
    "exp_22_4=pd.read_csv(\"exp_22_4.csv\")\n",
    "exp_22_5=pd.read_csv(\"exp_22_5.csv\")\n",
    "\n",
    "exp_23_1=pd.read_csv(\"exp_23_1.csv\")\n",
    "exp_23_2=pd.read_csv(\"exp_23_2.csv\")\n",
    "exp_23_3=pd.read_csv(\"exp_23_3.csv\")\n",
    "exp_23_4=pd.read_csv(\"exp_23_4.csv\")\n",
    "exp_23_5=pd.read_csv(\"exp_23_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_31_1=pd.read_csv(\"exp_31_1.csv\")\n",
    "exp_31_2=pd.read_csv(\"exp_31_2.csv\")\n",
    "exp_31_3=pd.read_csv(\"exp_31_3.csv\")\n",
    "exp_31_4=pd.read_csv(\"exp_31_4.csv\")\n",
    "exp_31_5=pd.read_csv(\"exp_31_5.csv\")\n",
    "\n",
    "exp_32_1=pd.read_csv(\"exp_32_1.csv\")\n",
    "exp_32_2=pd.read_csv(\"exp_32_2.csv\")\n",
    "exp_32_3=pd.read_csv(\"exp_32_3.csv\")\n",
    "exp_32_4=pd.read_csv(\"exp_32_4.csv\")\n",
    "exp_32_5=pd.read_csv(\"exp_32_5.csv\")\n",
    "\n",
    "exp_33_1=pd.read_csv(\"exp_33_1.csv\")\n",
    "exp_33_2=pd.read_csv(\"exp_33_2.csv\")\n",
    "exp_33_3=pd.read_csv(\"exp_33_3.csv\")\n",
    "exp_33_4=pd.read_csv(\"exp_33_4.csv\")\n",
    "exp_33_5=pd.read_csv(\"exp_33_5.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anglo_american",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
